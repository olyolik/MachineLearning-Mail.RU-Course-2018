# Домашние задания по курсу "Введение в Машинное обучение" от Mail.RU Group, 2018

## Домашнее задание #1
```
Цель: Требуется обучить классификатор, который будет распознавать рукописные цифры.

Метрика оценки: усредненная f1-measure по всем классам

Инструменты: Методы обучения, прогнозирования и подбора гиперпараметров следует реализовать самостоятельно. Из библиотеки sklearn можно использовать функции для разбивки данных (train_test_split) и вычисления метрик качества классификатора (classification_report).

Данные для обучения:
train-images-idx3-ubyte.gz: training set images (призакни)
train-labels-idx1-ubyte.gz: training set labels (метки)
Отложенный сет для замера качества (домашнее задание будет оцениваться, исходя из метрик на этом сете):
t10k-images-idx3-ubyte.gz: test set images (признаки)
t10k-labels-idx1-ubyte.gz: test set labels (метки)

Структура проекта:
У нас должна быть возможность запустить вашу программу. Поэтому обязательно предусмотрите наличие следующих скриптов в вашем проекте:
* train.py
* predict.py

Команды запуска должны выглядеть так:
python train.py —x_train_dir=</dir> —y_train_dir=</dir> —model_output_dir=</dir>
python predict.py —x_test_dir=<dir> —y_test_dir=</dir> —model_input_dir=</dir>

x_train_dir - путь к файлу, в котором лежат рекорды обучающей выборки
y_train_dir - путь к файлу, в котором лежат метки обучающей выборки
model_output_dir - путь к файлу, в который скрипт сохраняет обученную модель

x_test_dir - путь к файлу, в котором лежат рекорды тестовой выборки
y_test_dir - путь к файлу, в котором лежат метки тестовой выборки
model_input_dir - путь к файлу, из которого скрипт считывает обученную модель

Саму модель также следует залить в репозиторий.

Скрипты train.py и predict.py должны выводить на экран classification_report на обучающей выборке и на отложенном сете соответственно.
```

## Домашнее задание #3
```
Домашнее задание состоит из двух частей.

Часть 1 (5+ баллов)
Нужно реализовать класс для модели градиентного бустинга на деревьях (3 балла) и вспомогательные классы для функций потерь MSE (1 балл) и BCE (1 балл). Подробное описание задания смотрите в ноутбуке в архиве по ссылке внизу.

За что можно получить дополнительные баллы:
- Реализация ранней остановки обучения (1 балл)
- Реализация вычисления дополнительной метрики качества на каждой итерации (1 балл)
- Реализация бэггинга при обучении отдельных деревьев (1 балл)

Баллы начисляются, если соответствующие ячейки с проверками вида assert smth выполняются без ошибок.

Часть 2 (5+ баллов).
Нужно обучить какой-либо из рассмотренных в курсе ансамблей предсказывать трансферную стоимость футболиста из FIFA 18 Ultimate Team. Решение будет оцениваться по метрике MSE на тестовой выборке. Засчитывается только решение, качество которого на тестовой выборке окажется выше, чем у бейзлайна (см. ноутбук).

Данные для обучения - train_with_targets.csv, столбец с целевой переменной - price_ps4.
Для отправки решения заполните столбец price_ps4 в файле test_submission.csv предсказаниями своей модели на признаках из файла test.csv (убедитесь, что порядок следования player_id верный).

Для обучения моделей следует использовать:
* (!)Свой класс для градиентного бустинга, реализованный выше
* Любые ансамбли из sklearn (RandomForestRegressor, GradientBoostingRegressor, ...)
* Любые фреймворки для градиентного бустинга (XGBoost, LightGBM, CatBoost, ...)
* (!)Стекинг/блендинг (свой или тот, что был реализован на лекциях)
* Подбор гиперпараметров с помощью RandomizedSearch / hyperopt / ...

Использование пунктов с (!) может накинуть дополнительных баллов за задание (по 1 баллу за пункт, т.е. максимум 2 дополнительных балла).
Для обработки текстовых и категориальных признаков можете использовать все, что найдете полезным.

Как будет оцениваться вторая часть:
MSE < MSE(baseline) * 0.65: 5 баллов or
MSE < MSE(baseline) * 0.75: 4 балла or
MSE < MSE(baseline) * 0.85: 3 балла or
MSE < MSE(baseline) * 0.90: 2 балла or
MSE < MSE(baseline) * 1.00: 1 балл or
MSE >= MSE(baseline): 0 баллов

Формат сдачи
Решение должно состоять из:
- заполненного ноутбука ensembles_homework.ipynb
- файла test_submission.csv с предсказаниями для тестовой выборки
- (опционально) обученная модель

```

## Домашнее задание #4
```
Это домашнее задание посвящено алгоритму кластеризации k-means. Стартовый код в ноутбуке kmeans_homework.ipynb содержит:
Реализацию k-means
Подгрузку данных MNIST
Вычисление accuracy для полученного результата

Вам необходимо дополнить ноутбук реализацией k-means++, которая будет превосходить базовый k-means по качеству кластеризации при числе итераций, равным 50 (параметр iter_num=50). Дополнительные балы будут начислены, если вы покажете, что ваша реализация k-means++ превосходит базовый алгоритм по двум метрикам кластеризации, которые были разобраны на последней лекции (можно использовать их реализацию из scikit-learn).

Начисление баллов:

Реализация k-menas++: 5 баллов
Эта реализация превосходит базовый k-means при 50 итерациях: 3 балла
Использование метрик кластеризации: 2 балла
```
